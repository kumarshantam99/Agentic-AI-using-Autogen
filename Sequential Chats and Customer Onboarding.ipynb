{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n",
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kshantam\\Time series forecasting\\Agentic AI\\env\\Lib\\site-packages\\flaml\\__init__.py:20: UserWarning: flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "  warnings.warn(\"flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\")\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the needed agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 01-13 11:48:36] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding Personal Information Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 01-13 11:48:37] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding Topic preference Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 01-13 11:48:37] {129} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer Engagement Agent\",\n",
    "    system_message='''You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you get started with our product.\"\n",
    "            \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into as JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what topics you are \"\n",
    "                \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the onboarding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kshantam\\Time series forecasting\\Agentic AI\\env\\Lib\\site-packages\\autogen\\agentchat\\chat.py:47: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "Shantam\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you for providing your name. Could you also share your location with me?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "Delhi\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Topic preference Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "{\n",
      "  \"name\": \"Shantam\",\n",
      "  \"location\": \"Delhi\"\n",
      "}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Topic preference Agent):\n",
      "\n",
      "agentic ai\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer Engagement Agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "{\n",
      "  \"name\": \"Shantam\",\n",
      "  \"location\": \"Delhi\"\n",
      "}\n",
      "Shantam from Delhi is interested in reading about agentic AI.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer Engagement Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hey Shantam from Delhi! Did you know that agentic AI, which refers to AI systems that can act autonomously on behalf of a user, is becoming more prevalent in our everyday lives? From virtual assistants like Siri and Alexa to self-driving cars, agentic AI is revolutionizing how we interact with technology. It's amazing to think about how far we've come in integrating AI into our daily routines! What kind of agentic AI applications are you most excited about exploring further?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the summary and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Shantam\",\n",
      "  \"location\": \"Delhi\"\n",
      "}\n",
      "\n",
      "\n",
      "Shantam from Delhi is interested in reading about agentic AI.\n",
      "\n",
      "\n",
      "Shantam from Delhi is interested in reading about agentic AI, which refers to AI systems that can act autonomously on behalf of a user. Agentic AI is becoming more prevalent in our everyday lives, revolutionizing how we interact with technology.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.00014850000000000003, 'gpt-3.5-turbo-0125': {'cost': 0.00014850000000000003, 'prompt_tokens': 186, 'completion_tokens': 37, 'total_tokens': 223}}, 'usage_excluding_cached_inference': {'total_cost': 0.00014850000000000003, 'gpt-3.5-turbo-0125': {'cost': 0.00014850000000000003, 'prompt_tokens': 186, 'completion_tokens': 37, 'total_tokens': 223}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 5.8e-05, 'gpt-3.5-turbo-0125': {'cost': 5.8e-05, 'prompt_tokens': 71, 'completion_tokens': 15, 'total_tokens': 86}}, 'usage_excluding_cached_inference': {'total_cost': 5.8e-05, 'gpt-3.5-turbo-0125': {'cost': 5.8e-05, 'prompt_tokens': 71, 'completion_tokens': 15, 'total_tokens': 86}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.000371, 'gpt-3.5-turbo-0125': {'cost': 0.000371, 'prompt_tokens': 292, 'completion_tokens': 150, 'total_tokens': 442}}, 'usage_excluding_cached_inference': {'total_cost': 0.000371, 'gpt-3.5-turbo-0125': {'cost': 0.000371, 'prompt_tokens': 292, 'completion_tokens': 150, 'total_tokens': 442}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
